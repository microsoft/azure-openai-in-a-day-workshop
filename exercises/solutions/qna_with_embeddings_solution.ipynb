{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure OpenAI Service - Q&A with semantic answering tutorial\n",
    "\n",
    "In this tutorial, you'll build a simple Q&A system, that can give semantic answers to questions. Three sample documents from the Azure documentation are provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tiktoken\n",
    "import openai\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from openai.embeddings_utils import cosine_similarity\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure Azure OpenAI Service API\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2022-12-01\"\n",
    "openai.api_base = os.getenv('OPENAI_API_BASE')\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Define embedding model and encoding\n",
    "EMBEDDING_MODEL = 'text-embedding-ada-002'\n",
    "EMBEDDING_ENCODING = 'cl100k_base'\n",
    "EMBEDDING_CHUNK_SIZE = 8000\n",
    "COMPLETION_MODEL = 'text-davinci-003'\n",
    "\n",
    "# initialize tiktoken for encoding text\n",
    "encoding = tiktoken.get_encoding(EMBEDDING_ENCODING)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's read the documents in `/data/qna/*.txt`, which are our sample documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 documents\n",
      "Content:  # What is conversational language understanding? Conversational language unders... \n",
      "---> Tokens: 1341\n",
      "\n",
      "Content:  # What is Azure OpenAI? The Azure OpenAI service provides REST API access to Op... \n",
      "---> Tokens: 1891\n",
      "\n",
      "Content:  # What is Azure Cognitive Services Translator? Translator Service is a cloud-ba... \n",
      "---> Tokens: 739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# list all files in the samples directory\n",
    "samples_dir = os.path.join(os.getcwd(), \"../../data/qna/\")\n",
    "sample_files = os.listdir(samples_dir)\n",
    "\n",
    "# read each file and remove and newlines (better for embeddings later)\n",
    "documents = []\n",
    "for file in sample_files:\n",
    "    with open(os.path.join(samples_dir, file), \"r\") as f:\n",
    "        content = f.read()\n",
    "        content = content.replace(\"\\n\", \" \")\n",
    "        content = content.replace(\"  \", \" \")\n",
    "        documents.append(content)\n",
    "\n",
    "# print some stats about the documents\n",
    "print(f\"Loaded {len(documents)} documents\")\n",
    "for doc in documents:\n",
    "    num_tokens = len(encoding.encode(doc))\n",
    "    print(f\"Content: {doc[:80]}... \\n---> Tokens: {num_tokens}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all documents loaded, we can embed them using our embedding model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n",
      "1536\n",
      "1536\n"
     ]
    }
   ],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "def get_embedding(text):\n",
    "    return openai.Embedding.create(input=text, engine=EMBEDDING_MODEL)[\"data\"][0][\"embedding\"]\n",
    "\n",
    "# Create embeddings for all docs\n",
    "embeddings = [get_embedding(doc) for doc in documents]\n",
    "\n",
    "# print some stats about the embeddings\n",
    "for e in embeddings:\n",
    "    print(len(e))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our embeddings, we can try to ask some questions and see if it retrieves the correct document. You can try the following questions:\n",
    "\n",
    "* what is azure openai service?\n",
    "* can translator be fine tuned?\n",
    "* what is the difference between luis and clu?\n",
    "* what is form recognizer? (should yield no result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity to overview_clu.txt is 0.7739918312624845\n",
      "Similarity to overview_openai.txt is 0.8674443713390149\n",
      "Similarity to overview_translator.txt is 0.7915684774211917\n",
      "Matching document is overview_openai.txt\n"
     ]
    }
   ],
   "source": [
    "# create embedding for question\n",
    "question = \"what is azure openai service?\"\n",
    "qe = get_embedding(question)\n",
    "\n",
    "# calculate cosine similarity between question and each document\n",
    "similaries = [cosine_similarity(qe, e) for e in embeddings]\n",
    "\n",
    "# Get the matching document, in this case we just use argmax of similarities\n",
    "max_i = np.argmax(similaries)\n",
    "\n",
    "# print some stats about the similarities\n",
    "for i, s in enumerate(similaries):\n",
    "    print(f\"Similarity to {sample_files[i]} is {s}\")\n",
    "print(f\"Matching document is {sample_files[max_i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question was: what is azure openai service?\n",
      "Retrieved answer was:  Azure OpenAI Service provides REST API access to OpenAI's powerful language models, including the GPT-3, Codex and Embeddings model series. Users can access the service through REST APIs, Python SDK, or the web-based interface in the Azure OpenAI Studio.\n"
     ]
    }
   ],
   "source": [
    "# Generate a prompt that we use for completion, in this case we put the matched document and the question in the prompt\n",
    "prompt = f\"\"\"\n",
    "Content:\n",
    "{documents[max_i]}\n",
    "Please answer the question below using only the content from above. If you don't know the answer or can't find it, say \"I couldn't find the answer\".\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "# get response from completion model\n",
    "response = openai.Completion.create(\n",
    "    engine=COMPLETION_MODEL,\n",
    "    prompt=prompt,\n",
    "    temperature=0.7,\n",
    "    max_tokens=500,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    stop=None\n",
    ")\n",
    "answer = response['choices'][0]['text']\n",
    "\n",
    "# print the question and answer\n",
    "print(f\"Question was: {question}\\nRetrieved answer was: {answer}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, that worked. Now we should have a simple understanding how Q&A can work using OpenAI embeddings and completions. Next step would be:\n",
    "\n",
    "* Chunking of longer documents (you might run into token limits for embeddings and the answering prompt)\n",
    "* Usage of a vector database (pinecone, redis, etc.) to scale the search part to a larger amount of documents\n",
    "* Evaluation of the top k results, instead of just the best matching document\n",
    "* ...and a few more!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-qna-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4ee1bbf3137c7ea9420c4fd488a55642063e5739fe2a7286130d9ba47405b69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
